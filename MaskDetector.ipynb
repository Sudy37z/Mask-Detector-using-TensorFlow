{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e3a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, models\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11a03e",
   "metadata": {},
   "source": [
    "# Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5fe067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding\n",
    "label_code = {'mask_weared_incorrect':0,'with_mask':1,'without_mask':2}\n",
    "label_decode = ['mask_weared_incorrect','with_mask','without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bc9cdb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"D:\\Mask detector\\Dataset\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "EPOCHS = 70\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a145097",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split = 0.2)\n",
    "\n",
    "val_gen = ImageDataGenerator(validation_split=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b823577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7188 images belonging to 3 classes.\n",
      "Found 1794 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "SEED = 24\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = val_gen.flow_from_directory(\n",
    "    PATH,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34dcf1",
   "metadata": {},
   "source": [
    "# Building CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57c579e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a42431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d458ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, verbose=1)\n",
    "checkpoint = ModelCheckpoint('mask_model.h5', save_best_only=True, verbose=1)\n",
    "lr_reduce = ReduceLROnPlateau(patience=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8be17cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(amsgrad=True),\n",
    "    loss='categorical_crossentropy',\n",
    "#     our data classes are perfectly balanced so I'm able to use simple accuracy metric\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, checkpoint, lr_reduce]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585c774",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "c06dab0afc86e98d168378d6959dc6426e4ae057bc69bff2fc6bdf39c7bc31bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
